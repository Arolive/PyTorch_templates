{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used as an example is an image data stored as a single csv file with each row representing an image. Each image is 48*48 pixel stored as a vector of length 2304. The initial column is the emotion represented to each column. The types of emotions are present. Happy, Sad and fear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step includes,\n",
    "    1. Reading the data file and seperating images and labels\n",
    "    2. Train test split\n",
    "    3. Normalization\n",
    "    4. Creating batch process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating category to label encodoing and the inverted mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls2id = {\"Happy\": 0, \"Sad\": 1, \"Fear\": 2}\n",
    "id2cls = [\"Happy\", \"Sad\", \"Fear\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining data length, batch size, path of the dataset and the device to use for computation. CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = 10817\n",
    "BATCHSIZE = 10\n",
    "PATH = \"data/FER2013_csv.csv\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are gong to define two ways to process the data. Using the pytorch inbuild dataloader with customization and seperate one from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using pytorch functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "1. First we are defining the transformation has to be applied on the images after loading. Inclues normalization. Other transformations can be found <a href=\"https://pytorch.org/docs/stable/torchvision/transforms.html\">here</a>.\n",
    "    \n",
    "2. Next step is to define custom dataset reader. To use the code for any other dataset all is required to change the functions defined in the class CustomDatasetFromCSV.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints 10817\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(0, 255)])\n",
    "\n",
    "class CustomDatasetFromCSV(Dataset):\n",
    "    def __init__(self, csv_path, transform = None):\n",
    "        self.data    = pd.read_csv(csv_path)\n",
    "        ## For onehot encodng\n",
    "        #self.labels  = pd.get_dummies(self.data['emotion']).values\n",
    "        ## For label encoding\n",
    "        self.labels  = (self.data['emotion']).values\n",
    "        ## End of encoding\n",
    "        print(\"Number of datapoints\", len(self.labels))\n",
    "        self.height  = 48\n",
    "        self.width   = 48\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label        = cls2id[self.labels[index]]\n",
    "        pixels       = self.data[self.data.columns[1:]].values[index].astype(np.float)\n",
    "        pixels       = pixels.reshape(self.height, self.width)\n",
    "        if self.transform:\n",
    "            pixels = self.transform(pixels)\n",
    "        return pixels, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "dataset = CustomDatasetFromCSV(PATH, transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split the dataset using pytorch random_split and build the  trainloader and testloader using pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split and batch cration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_length      = round(0.7 * datalen)\n",
    "test_length       = round(0.3 * datalen)\n",
    "\n",
    "trainset, testset = random_split(dataset, [train_length, test_length])\n",
    "\n",
    "trainloader       = torch.utils.data.DataLoader(trainset, batch_size = BATCHSIZE, shuffle = True, num_workers = 0)\n",
    "testloader        = torch.utils.data.DataLoader(testset , batch_size = BATCHSIZE, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom function from scratch to process the data is devided into four functions.\n",
    "\n",
    "1. load_data()    : To load the data and normalize it and also doing the other required steps to create the image.\n",
    "2. loader()       : Loader calls load_data to load data and then tranform the data to tensor and make encofing of the labels.\n",
    "3. data_split()   : To split the dataset into rain and test.\n",
    "4. create_batch() : To create random batch with mentioned size. It returns a file which upon calling works same as dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(PATH):\n",
    "    data     = pd.read_csv(PATH)\n",
    "    labels   = data[\"emotion\"]\n",
    "    data     = data.drop([\"emotion\"], axis = 1)\n",
    "    images   = np.array(data.values).reshape(len(data.values), 48, 48)\n",
    "    return images, labels\n",
    "    \n",
    "def loader(PATH):\n",
    "    images, labels = load_data(PATH)\n",
    "    images = torch.tensor(images)\n",
    "    images = images.view(images.shape[0], -1, images.shape[1], images.shape[2])\n",
    "\n",
    "    target = []\n",
    "    for label in labels.values:\n",
    "        target.append(cls2id[label])\n",
    "    target = torch.tensor(target)\n",
    "    \n",
    "    return images, target\n",
    "\n",
    "def data_split(X, Y, test_size, shuffle = True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = test_size, shuffle = shuffle)\n",
    "    return(X_train, X_test, Y_train, Y_test)\n",
    "\n",
    "def create_batch(X, Y, batch_size = 1):\n",
    "    batch_x = [X[i: i + batch_size] for i in range(0, len(X), batch_size)]\n",
    "    batch_y = [Y[i: i + batch_size] for i in range(0, len(Y), batch_size)] \n",
    "    return list(zip(batch_x, batch_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, target = loader(PATH)\n",
    "train_X, test_X, train_Y, test_Y = data_split(images, target, test_size = 0.3) \n",
    "trainloaderCustom = create_batch(train_X, train_Y, batch_size = BATCHSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to perform a time comparison to run a for loop over the data sing both our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time(data):\n",
    "    start = time.time()\n",
    "    length = len(data)\n",
    "    pbar = tqdm(data, total = length, ncols = 800)\n",
    "    for inputs, labels in pbar:\n",
    "        inputs = inputs.to(device)\n",
    "        inputs = inputs.type(torch.cuda.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "    end = time.time()\n",
    "    print(\"Time taken {} sec\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbuild one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847db5f3da87473888fc4974af8e2fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=758.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken 465.165155172348 sec\n"
     ]
    }
   ],
   "source": [
    "test_time(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe751c8e3b74e9a99ee88f889b80837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=758.0), HTML(value='')), layout=Layout(di…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time taken 0.19699788093566895 sec\n"
     ]
    }
   ],
   "source": [
    "test_time(trainloaderCustom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some unknon reason inbuild one takes almost 3000 time more time than the other one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
